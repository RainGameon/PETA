[INFO 12:56:20] pymarl Running command 'my_main'
[INFO 12:56:20] pymarl Started run with ID "103"
[DEBUG 12:56:20] pymarl Starting Heartbeat
[DEBUG 12:56:20] my_main Started
SUNMENGYAO____50____________________
cuda 11.1
SUNMENGYAO________________________args.device=cuda:0
[INFO 12:56:20] my_main device:cuda:0
[INFO 12:56:20] my_main Experiment Parameters:
[INFO 12:56:20] my_main 

{   'action_selector': 'epsilon_greedy',
    'additional_update': True,
    'adv_hypernet_embed': 64,
    'adv_hypernet_layers': 1,
    'agent': 'rnn_fast',
    'agent_output_type': 'q',
    'atol_memory': 0.0013,
    'attend_reg_coef': 0.001,
    'batch_size': 32,
    'batch_size_run': 1,
    'buffer_cpu_only': False,
    'buffer_size': 5000,
    'buffer_size_update': 5000,
    'burn_in_period': 32,
    'checkpoint_path': '',
    'config_name': '',
    'critic_lr': 0.0005,
    'curiosity_decay': True,
    'curiosity_decay_cycle': 200000,
    'curiosity_decay_rate': 0.9,
    'curiosity_decay_stop': 0.01,
    'curiosity_scale': 0.2,
    'delta_cover_type': 1,
    'double_q': True,
    'ec_buffer_embedder_update_interval': 10000,
    'ec_buffer_stats_update_interval': 200,
    'emb_out_type': 3,
    'emb_training_batch': 102400,
    'emb_training_mini_batch': 1024,
    'emdqn_buffer_size': 1000000,
    'emdqn_latent_dim': 4,
    'emdqn_loss_weight': 0.1,
    'encoder_type': 1,
    'env': 'sc2',
    'env_args': {   'continuing_episode': False,
                    'debug': False,
                    'difficulty': '7',
                    'game_version': None,
                    'heuristic_ai': False,
                    'heuristic_rest': False,
                    'map_name': '6h_vs_8z',
                    'move_amount': 2,
                    'obs_all_health': True,
                    'obs_instead_of_state': False,
                    'obs_last_action': False,
                    'obs_own_health': True,
                    'obs_pathing_grid': False,
                    'obs_terrain_height': False,
                    'obs_timestep_number': False,
                    'replay_dir': '',
                    'replay_prefix': '',
                    'reward_death_value': 10,
                    'reward_defeat': 0,
                    'reward_negative_scale': 0.5,
                    'reward_only_positive': True,
                    'reward_scale': True,
                    'reward_scale_rate': 20,
                    'reward_sparse': False,
                    'reward_win': 200,
                    'seed': 219928608,
                    'state_last_action': True,
                    'state_timestep_number': False,
                    'step_mul': 8},
    'epsilon_anneal_time': 50000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': False,
    'fixed_delta': True,
    'flag_stats_norm': True,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'hypernet_embed': 64,
    'individual_curiostiy': True,
    'individual_q_loss_weight': 0.01,
    'is_adv_attention': True,
    'is_batch_rl': False,
    'is_from_start': True,
    'is_minus_one': True,
    'is_prioritized_buffer': False,
    'is_save_buffer': False,
    'is_stop_gradient': True,
    'joint_random_policy_eps': 0.0,
    'label': 'default_label',
    'lambda_kl': 0.0001,
    'lambda_s': 0.1,
    'learner': 'qplex_curiosity_vdn_learner_ind',
    'learner_log_interval': 10000,
    'load_buffer_id': 0,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.0005,
    'mac': 'fast_mac',
    'mask_dead': False,
    'memory_emb_type': 3,
    'mixer': 'dmaq_qatten',
    'mixing_embed_dim': 32,
    'n_head': 4,
    'name': 'EMU_sc2_hard',
    'nonlinear': True,
    'num_circle': 1,
    'num_kernel': 4,
    'obs_agent_id': True,
    'obs_last_action': True,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'optimality_incentive': False,
    'optimality_type': 1,
    'predict2_vdn_target': True,
    'predict_vdn_target': True,
    'predictor_lr': 0.005,
    'prioritized_buffer_alpha': 0.5,
    'repeat_id': 1,
    'rewardnet_embed_size': 128,
    'rewardnet_head': 4,
    'rewardnet_used': True,
    'rewardnet_weight': 0.001,
    'rnn_hidden_dim': 64,
    'rtol_memory': 0.0,
    'runner': 'episode',
    'runner_log_interval': 10000,
    'save_buffer': False,
    'save_buffer_id': 0,
    'save_buffer_interval': 1000,
    'save_buffer_size': 10000,
    'save_memory_info': False,
    'save_model': True,
    'save_model_interval': 1000000,
    'save_replay': False,
    'seed': 219928608,
    'soft_update_tau': 0.005,
    'state_bias': True,
    't_EC_update': 0,
    't_max': 4050000,
    'target_update_interval': 200,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 32,
    'use_AEM': True,
    'use_cuda': True,
    'use_double_predict': False,
    'use_emdqn': True,
    'use_individual_Q': False,
    'use_qtotal_td': False,
    'use_tensorboard': True,
    'vdn_soft_update': True,
    'weighted_head': True}

[INFO 12:56:20] my_main saving tb_logs to results/tb_logs/sc2/6h_vs_8z/EMU_sc2_hard__2024-11-07_12-56-20
[INFO 12:56:24] my_main Beginning training for 4050000 timesteps
[INFO 12:56:24] absl No GL library found, so RGB rendering will be disabled. For software rendering install libosmesa.
[INFO 12:56:24] absl Launching SC2: /home/EMC/pymarl/3rdparty/StarCraftII/Versions/Base69232/SC2_x64 -listen 127.0.0.1 -port 41629 -dataDir /home/EMC/pymarl/3rdparty/StarCraftII/ -tempDir /tmp/sc-7ztcpi7y/ -headlessNoRender
[INFO 12:56:24] absl Connecting to: ws://127.0.0.1:41629/sc2api, attempt: 0, running: True
Version: B69232 (SC2.4.6-Publish)
Build: Oct 23 2018 01:43:04
Command Line: '"/home/EMC/pymarl/3rdparty/StarCraftII/Versions/Base69232/SC2_x64" -listen 127.0.0.1 -port 41629 -dataDir /home/EMC/pymarl/3rdparty/StarCraftII/ -tempDir /tmp/sc-7ztcpi7y/ -headlessNoRender'
Starting up...
Startup Phase 1 complete
[INFO 12:56:25] absl Connecting to: ws://127.0.0.1:41629/sc2api, attempt: 1, running: True
Startup Phase 2 complete
Creating stub renderer...
Listening on: 127.0.0.1:41629
Startup Phase 3 complete. Ready for commands.
[INFO 12:56:26] absl Connecting to: ws://127.0.0.1:41629/sc2api, attempt: 2, running: True
Requesting to join a single player game
Configuring interface options
Configure: raw interface enabled
Configure: feature layer interface disabled
Configure: score interface disabled
Configure: render interface disabled
Entering load game phase.
Launching next game.
Next launch phase started: 2
Next launch phase started: 3
Next launch phase started: 4
Next launch phase started: 5
Next launch phase started: 6
Next launch phase started: 7
Next launch phase started: 8
Game has started.
Sending ResponseJoinGame
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=1
SUNMENGYAO_______________runner: k=ep_length v=27
[INFO 12:56:31] my_main t_env: 27 / 4050000
[INFO 12:56:31] my_main Estimated time left: 50 minutes, 42 seconds. Time passed: 7 seconds
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=32
SUNMENGYAO_______________runner: k=ep_length v=914
[INFO 12:56:39] my_main Saving models to results/models/_6h_vs_8z/EMU_sc2_hard__2024-11-07_12-56-20/27
episode_num = 31 init soft_target_mac
episode_num = 32 init soft_target_mac
episode_num = 33 init soft_target_mac
episode_num = 34 init soft_target_mac
episode_num = 35 init soft_target_mac
episode_num = 36 init soft_target_mac
episode_num = 37 init soft_target_mac
episode_num = 38 init soft_target_mac
episode_num = 39 init soft_target_mac
episode_num = 40 init soft_target_mac
episode_num = 41 init soft_target_mac
episode_num = 42 init soft_target_mac
episode_num = 43 init soft_target_mac
episode_num = 44 init soft_target_mac
episode_num = 45 init soft_target_mac
episode_num = 46 init soft_target_mac
episode_num = 47 init soft_target_mac
episode_num = 48 init soft_target_mac
episode_num = 49 init soft_target_mac
episode_num = 50 init soft_target_mac
episode_num = 51 init soft_target_mac
episode_num = 52 init soft_target_mac
episode_num = 53 init soft_target_mac
episode_num = 54 init soft_target_mac
episode_num = 55 init soft_target_mac
episode_num = 56 init soft_target_mac
episode_num = 57 init soft_target_mac
episode_num = 58 init soft_target_mac
episode_num = 59 init soft_target_mac
episode_num = 60 init soft_target_mac
episode_num = 61 init soft_target_mac
episode_num = 62 init soft_target_mac
episode_num = 63 init soft_target_mac
episode_num = 64 init soft_target_mac
episode_num = 65 init soft_target_mac
episode_num = 66 init soft_target_mac
episode_num = 67 init soft_target_mac
episode_num = 68 init soft_target_mac
episode_num = 69 init soft_target_mac
episode_num = 70 init soft_target_mac
episode_num = 71 init soft_target_mac
episode_num = 72 init soft_target_mac
episode_num = 73 init soft_target_mac
episode_num = 74 init soft_target_mac
episode_num = 75 init soft_target_mac
episode_num = 76 init soft_target_mac
episode_num = 77 init soft_target_mac
episode_num = 78 init soft_target_mac
episode_num = 79 init soft_target_mac
episode_num = 80 init soft_target_mac
episode_num = 81 init soft_target_mac
episode_num = 82 init soft_target_mac
episode_num = 83 init soft_target_mac
episode_num = 84 init soft_target_mac
episode_num = 85 init soft_target_mac
episode_num = 86 init soft_target_mac
episode_num = 87 init soft_target_mac
episode_num = 88 init soft_target_mac
episode_num = 89 init soft_target_mac
episode_num = 90 init soft_target_mac
episode_num = 91 init soft_target_mac
episode_num = 92 init soft_target_mac
episode_num = 93 init soft_target_mac
episode_num = 94 init soft_target_mac
episode_num = 95 init soft_target_mac
episode_num = 96 init soft_target_mac
episode_num = 97 init soft_target_mac
episode_num = 98 init soft_target_mac
episode_num = 99 init soft_target_mac
[INFO 12:58:47] my_main Updated target network
[INFO 13:01:37] my_main Updated target network
Processing time for memory embedding: 2.574920654296875e-05
[INFO 13:02:03] my_main Recent Stats | t_env:      10005 | Episode:      431
battle_won_mean:           0.0000	curiosity_decay_cycle:   200000.0000	curiosity_decay_rate:      0.9000	curiosity_decay_stop:      0.0100
curiosity_scale:           0.2000	emdqn_curr_capacity:     777.0000	emdqn_loss:                0.0000	emdqn_weight:              0.1000
ep_length_mean:           27.0000	epsilon:                   1.0000	grad_norm:                 1.8306	loss:                      0.1189
num_circle:                1.0000	pred_total_reward:        -0.0037	q_taken_mean:             -0.0164	return_mean:               5.1064
return_std:                0.0000	rewardnet_loss:            6.7539	target_mean:               0.0293	td_error_abs:              0.2771
test_battle_won_mean:      0.0000	test_ep_length_mean:      28.5625	test_return_mean:          5.6190	test_return_std:           0.6607
vdn extrinsic rewards:     0.2290	vdn intrinsic rewards:     0.9839	vdn predict_grad_norm:     1.7471	vdn predict_mac_out_mean: -0.0231
vdn prediction loss:       4.9196	vdn soft_target_mac_out_next_mean: -0.0348	
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=431
SUNMENGYAO_______________runner: k=ep_length v=10001
[INFO 13:02:04] my_main t_env: 10028 / 4050000
[INFO 13:02:04] my_main Estimated time left: 1 days, 13 hours, 23 minutes, 6 seconds. Time passed: 5 minutes, 40 seconds
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=32
SUNMENGYAO_______________runner: k=ep_length v=732
[INFO 13:04:38] my_main Updated target network
