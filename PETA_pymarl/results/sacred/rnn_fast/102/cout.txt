[INFO 12:48:31] pymarl Running command 'my_main'
[INFO 12:48:31] pymarl Started run with ID "102"
[DEBUG 12:48:31] pymarl Starting Heartbeat
[DEBUG 12:48:31] my_main Started
SUNMENGYAO____50____________________
cuda 11.1
SUNMENGYAO________________________args.device=cuda:0
[INFO 12:48:31] my_main device:cuda:0
[INFO 12:48:31] my_main Experiment Parameters:
[INFO 12:48:31] my_main 

{   'action_selector': 'epsilon_greedy',
    'additional_update': True,
    'adv_hypernet_embed': 64,
    'adv_hypernet_layers': 1,
    'agent': 'rnn_fast',
    'agent_output_type': 'q',
    'atol_memory': 0.0013,
    'attend_reg_coef': 0.001,
    'batch_size': 32,
    'batch_size_run': 1,
    'buffer_cpu_only': False,
    'buffer_size': 5000,
    'buffer_size_update': 5000,
    'burn_in_period': 32,
    'checkpoint_path': '',
    'config_name': '',
    'critic_lr': 0.0005,
    'curiosity_decay': True,
    'curiosity_decay_cycle': 100000,
    'curiosity_decay_rate': 0.9,
    'curiosity_decay_stop': 0.0,
    'curiosity_scale': 0.0,
    'delta_cover_type': 1,
    'double_q': True,
    'ec_buffer_embedder_update_interval': 10000,
    'ec_buffer_stats_update_interval': 200,
    'emb_out_type': 3,
    'emb_training_batch': 102400,
    'emb_training_mini_batch': 1024,
    'emdqn_buffer_size': 1000000,
    'emdqn_latent_dim': 4,
    'emdqn_loss_weight': 0.1,
    'encoder_type': 1,
    'env': 'sc2',
    'env_args': {   'continuing_episode': False,
                    'debug': False,
                    'difficulty': '7',
                    'game_version': None,
                    'heuristic_ai': False,
                    'heuristic_rest': False,
                    'map_name': 'MMM2',
                    'move_amount': 2,
                    'obs_all_health': True,
                    'obs_instead_of_state': False,
                    'obs_last_action': False,
                    'obs_own_health': True,
                    'obs_pathing_grid': False,
                    'obs_terrain_height': False,
                    'obs_timestep_number': False,
                    'replay_dir': '',
                    'replay_prefix': '',
                    'reward_death_value': 10,
                    'reward_defeat': 0,
                    'reward_negative_scale': 0.5,
                    'reward_only_positive': True,
                    'reward_scale': True,
                    'reward_scale_rate': 20,
                    'reward_sparse': False,
                    'reward_win': 200,
                    'seed': 509375924,
                    'state_last_action': True,
                    'state_timestep_number': False,
                    'step_mul': 8},
    'epsilon_anneal_time': 50000,
    'epsilon_finish': 0.05,
    'epsilon_start': 1.0,
    'evaluate': False,
    'fixed_delta': True,
    'flag_stats_norm': True,
    'gamma': 0.99,
    'grad_norm_clip': 10,
    'hypernet_embed': 64,
    'individual_curiostiy': True,
    'individual_q_loss_weight': 0.01,
    'is_adv_attention': True,
    'is_batch_rl': False,
    'is_from_start': True,
    'is_minus_one': True,
    'is_prioritized_buffer': False,
    'is_save_buffer': False,
    'is_stop_gradient': True,
    'joint_random_policy_eps': 0.0,
    'label': 'default_label',
    'lambda_kl': 0.0001,
    'lambda_s': 0.1,
    'learner': 'qplex_curiosity_vdn_learner_ind',
    'learner_log_interval': 10000,
    'load_buffer_id': 0,
    'load_step': 0,
    'local_results_path': 'results',
    'log_interval': 10000,
    'lr': 0.0005,
    'mac': 'fast_mac',
    'mask_dead': False,
    'memory_emb_type': 3,
    'mixer': 'dmaq_qatten',
    'mixing_embed_dim': 32,
    'n_head': 4,
    'name': 'EMU_sc2_hard',
    'nonlinear': True,
    'num_circle': 1,
    'num_kernel': 4,
    'obs_agent_id': True,
    'obs_last_action': True,
    'optim_alpha': 0.99,
    'optim_eps': 1e-05,
    'optimality_incentive': False,
    'optimality_type': 1,
    'predict2_vdn_target': True,
    'predict_vdn_target': True,
    'predictor_lr': 0.005,
    'prioritized_buffer_alpha': 0.5,
    'repeat_id': 1,
    'rewardnet_embed_size': 128,
    'rewardnet_head': 4,
    'rewardnet_used': True,
    'rewardnet_weight': 0.001,
    'rnn_hidden_dim': 64,
    'rtol_memory': 0.0,
    'runner': 'episode',
    'runner_log_interval': 10000,
    'save_buffer': False,
    'save_buffer_id': 0,
    'save_buffer_interval': 1000,
    'save_buffer_size': 10000,
    'save_memory_info': False,
    'save_model': True,
    'save_model_interval': 1000000,
    'save_replay': False,
    'seed': 509375924,
    'soft_update_tau': 0.005,
    'state_bias': True,
    't_EC_update': 0,
    't_max': 4050000,
    'target_update_interval': 200,
    'test_greedy': True,
    'test_interval': 10000,
    'test_nepisode': 32,
    'use_AEM': True,
    'use_cuda': True,
    'use_double_predict': False,
    'use_emdqn': True,
    'use_individual_Q': False,
    'use_qtotal_td': False,
    'use_tensorboard': True,
    'vdn_soft_update': True,
    'weighted_head': True}

[INFO 12:48:31] my_main saving tb_logs to results/tb_logs/sc2/MMM2/EMU_sc2_hard__2024-11-07_12-48-31
[INFO 12:48:35] my_main Beginning training for 4050000 timesteps
[INFO 12:48:35] absl No GL library found, so RGB rendering will be disabled. For software rendering install libosmesa.
[INFO 12:48:35] absl Launching SC2: /home/EMC/pymarl/3rdparty/StarCraftII/Versions/Base69232/SC2_x64 -listen 127.0.0.1 -port 33633 -dataDir /home/EMC/pymarl/3rdparty/StarCraftII/ -tempDir /tmp/sc-f7o_7a1x/ -headlessNoRender
[INFO 12:48:35] absl Connecting to: ws://127.0.0.1:33633/sc2api, attempt: 0, running: True
Version: B69232 (SC2.4.6-Publish)
Build: Oct 23 2018 01:43:04
Command Line: '"/home/EMC/pymarl/3rdparty/StarCraftII/Versions/Base69232/SC2_x64" -listen 127.0.0.1 -port 33633 -dataDir /home/EMC/pymarl/3rdparty/StarCraftII/ -tempDir /tmp/sc-f7o_7a1x/ -headlessNoRender'
Starting up...
Startup Phase 1 complete
[INFO 12:48:36] absl Connecting to: ws://127.0.0.1:33633/sc2api, attempt: 1, running: True
Startup Phase 2 complete
Creating stub renderer...
Listening on: 127.0.0.1:33633
Startup Phase 3 complete. Ready for commands.
[INFO 12:48:37] absl Connecting to: ws://127.0.0.1:33633/sc2api, attempt: 2, running: True
Requesting to join a single player game
Configuring interface options
Configure: raw interface enabled
Configure: feature layer interface disabled
Configure: score interface disabled
Configure: render interface disabled
Entering load game phase.
Launching next game.
Next launch phase started: 2
Next launch phase started: 3
Next launch phase started: 4
Next launch phase started: 5
Next launch phase started: 6
Next launch phase started: 7
Next launch phase started: 8
Game has started.
Sending ResponseJoinGame
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=1
SUNMENGYAO_______________runner: k=ep_length v=42
[INFO 12:48:43] my_main t_env: 42 / 4050000
[INFO 12:48:43] my_main Estimated time left: 52 minutes, 31 seconds. Time passed: 7 seconds
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=32
SUNMENGYAO_______________runner: k=ep_length v=1044
[INFO 12:48:54] my_main Saving models to results/models/_MMM2/EMU_sc2_hard__2024-11-07_12-48-31/42
episode_num = 31 init soft_target_mac
episode_num = 32 init soft_target_mac
episode_num = 33 init soft_target_mac
episode_num = 34 init soft_target_mac
episode_num = 35 init soft_target_mac
episode_num = 36 init soft_target_mac
episode_num = 37 init soft_target_mac
episode_num = 38 init soft_target_mac
episode_num = 39 init soft_target_mac
episode_num = 40 init soft_target_mac
episode_num = 41 init soft_target_mac
episode_num = 42 init soft_target_mac
episode_num = 43 init soft_target_mac
episode_num = 44 init soft_target_mac
episode_num = 45 init soft_target_mac
episode_num = 46 init soft_target_mac
episode_num = 47 init soft_target_mac
episode_num = 48 init soft_target_mac
episode_num = 49 init soft_target_mac
episode_num = 50 init soft_target_mac
episode_num = 51 init soft_target_mac
episode_num = 52 init soft_target_mac
episode_num = 53 init soft_target_mac
episode_num = 54 init soft_target_mac
episode_num = 55 init soft_target_mac
episode_num = 56 init soft_target_mac
episode_num = 57 init soft_target_mac
episode_num = 58 init soft_target_mac
episode_num = 59 init soft_target_mac
episode_num = 60 init soft_target_mac
episode_num = 61 init soft_target_mac
episode_num = 62 init soft_target_mac
episode_num = 63 init soft_target_mac
episode_num = 64 init soft_target_mac
episode_num = 65 init soft_target_mac
episode_num = 66 init soft_target_mac
episode_num = 67 init soft_target_mac
episode_num = 68 init soft_target_mac
episode_num = 69 init soft_target_mac
episode_num = 70 init soft_target_mac
episode_num = 71 init soft_target_mac
episode_num = 72 init soft_target_mac
episode_num = 73 init soft_target_mac
episode_num = 74 init soft_target_mac
episode_num = 75 init soft_target_mac
episode_num = 76 init soft_target_mac
episode_num = 77 init soft_target_mac
episode_num = 78 init soft_target_mac
episode_num = 79 init soft_target_mac
episode_num = 80 init soft_target_mac
episode_num = 81 init soft_target_mac
episode_num = 82 init soft_target_mac
episode_num = 83 init soft_target_mac
episode_num = 84 init soft_target_mac
episode_num = 85 init soft_target_mac
episode_num = 86 init soft_target_mac
episode_num = 87 init soft_target_mac
episode_num = 88 init soft_target_mac
episode_num = 89 init soft_target_mac
episode_num = 90 init soft_target_mac
episode_num = 91 init soft_target_mac
episode_num = 92 init soft_target_mac
episode_num = 93 init soft_target_mac
episode_num = 94 init soft_target_mac
episode_num = 95 init soft_target_mac
episode_num = 96 init soft_target_mac
episode_num = 97 init soft_target_mac
episode_num = 98 init soft_target_mac
episode_num = 99 init soft_target_mac
[INFO 12:53:24] my_main Updated target network
Processing time for memory embedding: 1.8835067749023438e-05
[INFO 12:55:21] my_main Recent Stats | t_env:      10028 | Episode:      270
battle_won_mean:           0.0000	curiosity_decay_cycle:   100000.0000	curiosity_decay_rate:      0.9000	curiosity_decay_stop:      0.0000
curiosity_scale:           0.0000	emdqn_curr_capacity:     1241.0000	emdqn_loss:                0.0000	emdqn_weight:              0.1000
ep_length_mean:           42.0000	epsilon:                   1.0000	grad_norm:                 0.2543	loss:                      0.0084
num_circle:                1.0000	pred_total_reward:        -0.0189	q_taken_mean:             -0.0029	return_mean:               2.0045
return_std:                0.0000	rewardnet_loss:            0.4130	target_mean:               0.0026	td_error_abs:              0.0679
test_battle_won_mean:      0.0000	test_ep_length_mean:      32.6250	test_return_mean:          2.0411	test_return_std:           0.4427
vdn extrinsic rewards:     0.0482	vdn intrinsic rewards:     0.0000	vdn predict_grad_norm:     1.5750	vdn predict_mac_out_mean:  0.0082
vdn prediction loss:       4.4170	vdn soft_target_mac_out_next_mean:  0.0108	
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=270
SUNMENGYAO_______________runner: k=ep_length v=10021
[INFO 12:55:22] my_main t_env: 10063 / 4050000
[INFO 12:55:22] my_main Estimated time left: 1 days, 20 hours, 46 minutes, 14 seconds. Time passed: 6 minutes, 47 seconds
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=32
SUNMENGYAO_______________runner: k=ep_length v=1115
[INFO 12:59:14] my_main Updated target network
Processing time for memory embedding: 1.3113021850585938e-05
[INFO 13:04:07] my_main Recent Stats | t_env:      20047 | Episode:      575
battle_won_mean:           0.0000	curiosity_decay_cycle:   100000.0000	curiosity_decay_rate:      0.9000	curiosity_decay_stop:      0.0000
curiosity_scale:           0.0000	emdqn_curr_capacity:     6366.0000	emdqn_loss:                0.0122	emdqn_weight:              0.1000
ep_length_mean:           39.5574	epsilon:                   0.8095	grad_norm:                 0.1364	loss:                      0.0184
num_circle:                1.0000	pred_total_reward:         0.2587	q_taken_mean:              0.0072	return_mean:               1.9715
return_std:                0.2191	rewardnet_loss:            0.2460	target_mean:               0.0089	td_error_abs:              0.0584
test_battle_won_mean:      0.0000	test_ep_length_mean:      33.7344	test_return_mean:          2.5726	test_return_std:           0.4816
vdn extrinsic rewards:     0.0522	vdn intrinsic rewards:     0.0000	vdn predict_grad_norm:     1.0756	vdn predict_mac_out_mean:  0.2522
vdn prediction loss:       2.5899	vdn soft_target_mac_out_next_mean:  0.0311	
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=305
SUNMENGYAO_______________runner: k=ep_length v=10014
[INFO 13:04:09] my_main t_env: 20077 / 4050000
[INFO 13:04:09] my_main Estimated time left: 2 days, 10 hours, 50 minutes, 37 seconds. Time passed: 15 minutes, 34 seconds
SUNMENGYAO_______________runner: k=battle_won v=0
SUNMENGYAO_______________runner: k=n_episodes v=32
SUNMENGYAO_______________runner: k=ep_length v=1146
[INFO 13:05:02] my_main Updated target network
